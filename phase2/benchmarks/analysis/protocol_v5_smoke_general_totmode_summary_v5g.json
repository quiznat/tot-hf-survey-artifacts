{
  "series_id": "protocol_v5_smoke_general_totmode",
  "report_tag": "v5g",
  "model_id": "Qwen/Qwen3-Coder-Next:novita",
  "generated_utc": "2026-02-23T02:01:24Z",
  "task_summaries": [
    {
      "task_id": "digit-permutation-demo",
      "items_evaluated": 10,
      "runs_executed": 50,
      "tot_mode": "model_decompose_search",
      "tot_decomposition_rounds": 1,
      "tot_evaluator_mode": "rule_based",
      "success_rates": {
        "baseline-cot": 0.0,
        "baseline-cot-sc": 0.0,
        "baseline-react": 1.0,
        "baseline-single-path": 0.2,
        "tot-prototype": 1.0
      },
      "latency_ms_mean": {
        "baseline-cot": 2201.2,
        "baseline-cot-sc": 16977.3,
        "baseline-react": 13915.4,
        "baseline-single-path": 2327.5,
        "tot-prototype": 10642.2
      },
      "paired_comparison": [
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-cot-sc",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 10,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-react",
          "delta_ci_high": -1.0,
          "delta_ci_low": -1.0,
          "delta_success_rate": -1.0,
          "discordant_pairs": 10,
          "matched_items": 10,
          "mcnemar_p_holm": 0.01953125,
          "mcnemar_p_value": 0.001953125,
          "ties": 0
        },
        {
          "a_better": 0,
          "b_better": 2,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": -0.5,
          "delta_success_rate": -0.2,
          "discordant_pairs": 2,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.5,
          "ties": 8
        },
        {
          "a_better": 0,
          "b_better": 10,
          "condition_a": "baseline-cot",
          "condition_b": "tot-prototype",
          "delta_ci_high": -1.0,
          "delta_ci_low": -1.0,
          "delta_success_rate": -1.0,
          "discordant_pairs": 10,
          "matched_items": 10,
          "mcnemar_p_holm": 0.01953125,
          "mcnemar_p_value": 0.001953125,
          "ties": 0
        },
        {
          "a_better": 0,
          "b_better": 10,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-react",
          "delta_ci_high": -1.0,
          "delta_ci_low": -1.0,
          "delta_success_rate": -1.0,
          "discordant_pairs": 10,
          "matched_items": 10,
          "mcnemar_p_holm": 0.01953125,
          "mcnemar_p_value": 0.001953125,
          "ties": 0
        },
        {
          "a_better": 0,
          "b_better": 2,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": -0.5,
          "delta_success_rate": -0.2,
          "discordant_pairs": 2,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.5,
          "ties": 8
        },
        {
          "a_better": 0,
          "b_better": 10,
          "condition_a": "baseline-cot-sc",
          "condition_b": "tot-prototype",
          "delta_ci_high": -1.0,
          "delta_ci_low": -1.0,
          "delta_success_rate": -1.0,
          "discordant_pairs": 10,
          "matched_items": 10,
          "mcnemar_p_holm": 0.01953125,
          "mcnemar_p_value": 0.001953125,
          "ties": 0
        },
        {
          "a_better": 8,
          "b_better": 0,
          "condition_a": "baseline-react",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 1.0,
          "delta_ci_low": 0.5,
          "delta_success_rate": 0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.046875,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-react",
          "condition_b": "tot-prototype",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-single-path",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.046875,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        }
      ],
      "source_report_json": "/Users/quiznat/Desktop/Tree_of_Thought/phase2/benchmarks/analysis/digit_permutation_demo_base_smoke_report_qwen_qwen3_coder_next_novita_v5g.json"
    },
    {
      "task_id": "game24-demo",
      "items_evaluated": 10,
      "runs_executed": 50,
      "tot_mode": "model_decompose_search",
      "tot_decomposition_rounds": 1,
      "tot_evaluator_mode": "rule_based",
      "success_rates": {
        "baseline-cot": 0.0,
        "baseline-cot-sc": 0.0,
        "baseline-react": 0.0,
        "baseline-single-path": 0.2,
        "tot-prototype": 0.8
      },
      "latency_ms_mean": {
        "baseline-cot": 2099.4,
        "baseline-cot-sc": 30826.3,
        "baseline-react": 23993.5,
        "baseline-single-path": 3484.9,
        "tot-prototype": 41060.0
      },
      "paired_comparison": [
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-cot-sc",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-react",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 2,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": -0.5,
          "delta_success_rate": -0.2,
          "discordant_pairs": 2,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.5,
          "ties": 8
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-cot",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.078125,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-react",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 2,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": -0.5,
          "delta_success_rate": -0.2,
          "discordant_pairs": 2,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.5,
          "ties": 8
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-cot-sc",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.078125,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 2,
          "condition_a": "baseline-react",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": -0.5,
          "delta_success_rate": -0.2,
          "discordant_pairs": 2,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.5,
          "ties": 8
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-react",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.078125,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 6,
          "condition_a": "baseline-single-path",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.3,
          "delta_ci_low": -0.9,
          "delta_success_rate": -0.6,
          "discordant_pairs": 6,
          "matched_items": 10,
          "mcnemar_p_holm": 0.21875,
          "mcnemar_p_value": 0.03125,
          "ties": 4
        }
      ],
      "source_report_json": "/Users/quiznat/Desktop/Tree_of_Thought/phase2/benchmarks/analysis/game24_demo_base_smoke_report_qwen_qwen3_coder_next_novita_v5g.json"
    },
    {
      "task_id": "linear2-demo",
      "items_evaluated": 10,
      "runs_executed": 50,
      "tot_mode": "model_decompose_search",
      "tot_decomposition_rounds": 1,
      "tot_evaluator_mode": "rule_based",
      "success_rates": {
        "baseline-cot": 0.0,
        "baseline-cot-sc": 0.0,
        "baseline-react": 0.8,
        "baseline-single-path": 0.0,
        "tot-prototype": 0.9
      },
      "latency_ms_mean": {
        "baseline-cot": 4897.0,
        "baseline-cot-sc": 22032.4,
        "baseline-react": 15765.7,
        "baseline-single-path": 4203.0,
        "tot-prototype": 16116.4
      },
      "paired_comparison": [
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-cot-sc",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-react",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0546875,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 9,
          "condition_a": "baseline-cot",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.7,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.9,
          "discordant_pairs": 9,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0390625,
          "mcnemar_p_value": 0.00390625,
          "ties": 1
        },
        {
          "a_better": 0,
          "b_better": 8,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-react",
          "delta_ci_high": -0.5,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0546875,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 0,
          "b_better": 9,
          "condition_a": "baseline-cot-sc",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.7,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.9,
          "discordant_pairs": 9,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0390625,
          "mcnemar_p_value": 0.00390625,
          "ties": 1
        },
        {
          "a_better": 8,
          "b_better": 0,
          "condition_a": "baseline-react",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 1.0,
          "delta_ci_low": 0.5,
          "delta_success_rate": 0.8,
          "discordant_pairs": 8,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0546875,
          "mcnemar_p_value": 0.0078125,
          "ties": 2
        },
        {
          "a_better": 1,
          "b_better": 2,
          "condition_a": "baseline-react",
          "condition_b": "tot-prototype",
          "delta_ci_high": 0.2,
          "delta_ci_low": -0.4,
          "delta_success_rate": -0.1,
          "discordant_pairs": 3,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 7
        },
        {
          "a_better": 0,
          "b_better": 9,
          "condition_a": "baseline-single-path",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.7,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.9,
          "discordant_pairs": 9,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0390625,
          "mcnemar_p_value": 0.00390625,
          "ties": 1
        }
      ],
      "source_report_json": "/Users/quiznat/Desktop/Tree_of_Thought/phase2/benchmarks/analysis/linear2_demo_base_smoke_report_qwen_qwen3_coder_next_novita_v5g.json"
    },
    {
      "task_id": "subset-sum-demo",
      "items_evaluated": 10,
      "runs_executed": 50,
      "tot_mode": "model_decompose_search",
      "tot_decomposition_rounds": 1,
      "tot_evaluator_mode": "rule_based",
      "success_rates": {
        "baseline-cot": 0.1,
        "baseline-cot-sc": 0.1,
        "baseline-react": 0.3,
        "baseline-single-path": 0.5,
        "tot-prototype": 1.0
      },
      "latency_ms_mean": {
        "baseline-cot": 8092.3,
        "baseline-cot-sc": 39522.1,
        "baseline-react": 17043.9,
        "baseline-single-path": 3492.0,
        "tot-prototype": 10867.7
      },
      "paired_comparison": [
        {
          "a_better": 0,
          "b_better": 0,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-cot-sc",
          "delta_ci_high": 0.0,
          "delta_ci_low": 0.0,
          "delta_success_rate": 0.0,
          "discordant_pairs": 0,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 1.0,
          "ties": 10
        },
        {
          "a_better": 1,
          "b_better": 3,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-react",
          "delta_ci_high": 0.2,
          "delta_ci_low": -0.6,
          "delta_success_rate": -0.2,
          "discordant_pairs": 4,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.625,
          "ties": 6
        },
        {
          "a_better": 0,
          "b_better": 4,
          "condition_a": "baseline-cot",
          "condition_b": "baseline-single-path",
          "delta_ci_high": -0.1,
          "delta_ci_low": -0.7,
          "delta_success_rate": -0.4,
          "discordant_pairs": 4,
          "matched_items": 10,
          "mcnemar_p_holm": 0.75,
          "mcnemar_p_value": 0.125,
          "ties": 6
        },
        {
          "a_better": 0,
          "b_better": 9,
          "condition_a": "baseline-cot",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.7,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.9,
          "discordant_pairs": 9,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0390625,
          "mcnemar_p_value": 0.00390625,
          "ties": 1
        },
        {
          "a_better": 1,
          "b_better": 3,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-react",
          "delta_ci_high": 0.2,
          "delta_ci_low": -0.6,
          "delta_success_rate": -0.2,
          "discordant_pairs": 4,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.625,
          "ties": 6
        },
        {
          "a_better": 0,
          "b_better": 4,
          "condition_a": "baseline-cot-sc",
          "condition_b": "baseline-single-path",
          "delta_ci_high": -0.1,
          "delta_ci_low": -0.7,
          "delta_success_rate": -0.4,
          "discordant_pairs": 4,
          "matched_items": 10,
          "mcnemar_p_holm": 0.75,
          "mcnemar_p_value": 0.125,
          "ties": 6
        },
        {
          "a_better": 0,
          "b_better": 9,
          "condition_a": "baseline-cot-sc",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.7,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.9,
          "discordant_pairs": 9,
          "matched_items": 10,
          "mcnemar_p_holm": 0.0390625,
          "mcnemar_p_value": 0.00390625,
          "ties": 1
        },
        {
          "a_better": 2,
          "b_better": 4,
          "condition_a": "baseline-react",
          "condition_b": "baseline-single-path",
          "delta_ci_high": 0.3,
          "delta_ci_low": -0.7,
          "delta_success_rate": -0.2,
          "discordant_pairs": 6,
          "matched_items": 10,
          "mcnemar_p_holm": 1.0,
          "mcnemar_p_value": 0.6875,
          "ties": 4
        },
        {
          "a_better": 0,
          "b_better": 7,
          "condition_a": "baseline-react",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.4,
          "delta_ci_low": -1.0,
          "delta_success_rate": -0.7,
          "discordant_pairs": 7,
          "matched_items": 10,
          "mcnemar_p_holm": 0.125,
          "mcnemar_p_value": 0.015625,
          "ties": 3
        },
        {
          "a_better": 0,
          "b_better": 5,
          "condition_a": "baseline-single-path",
          "condition_b": "tot-prototype",
          "delta_ci_high": -0.2,
          "delta_ci_low": -0.8,
          "delta_success_rate": -0.5,
          "discordant_pairs": 5,
          "matched_items": 10,
          "mcnemar_p_holm": 0.4375,
          "mcnemar_p_value": 0.0625,
          "ties": 5
        }
      ],
      "source_report_json": "/Users/quiznat/Desktop/Tree_of_Thought/phase2/benchmarks/analysis/subset_sum_demo_base_smoke_report_qwen_qwen3_coder_next_novita_v5g.json"
    }
  ]
}